{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telco Churn Prediction\n",
    "Customer churn, also known as customer attrition, is when a customer chooses to stop using your products or services. With each customer who churns, there are usually early indicators that could have been uncovered with churn analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries we'll need\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "#visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#show all cols\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data\n",
    "Data obtained from https://www.kaggle.com/blastchar/telco-customer-churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "data_path = \"/Users/badisamosesane/Desktop/sais_uig/btc_customer_churn/data\"\n",
    "df = pd.read_csv(f'{data_path}/WA_Fn_UseC_Telco_Customer_churn.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Understanding the data\n",
    "We now try to understand the data we are dealing with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data types for all fields\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View the unique data by column. \n",
    "There are a few columns we can convert to binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print each item in df cols, see item.unique()\n",
    "# gives an idea which can be converted to binary\n",
    "for item in df.columns:\n",
    "    print(item)\n",
    "    print (df[item].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert strings to lowercase.\n",
    "all strings to lower case in cols fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert colsname to lower case, throw exception couldnt convert\n",
    "for item in df.columns:\n",
    "    try:\n",
    "        df[item] = df[item].str.lower()\n",
    "    except:\n",
    "        print(item, \"couldn't convert\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert all yes and no to 0's & 1's so our classifier can use this data.\n",
    "all cols with value yes or no, convert to 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list columns to convert\n",
    "columns_to_convert = ['Partner', \n",
    "                      'Dependents', \n",
    "                      'PhoneService', \n",
    "                      'PaperlessBilling', \n",
    "                      'Churn']\n",
    "\n",
    "for item in columns_to_convert:\n",
    "    df[item].replace(to_replace='yes', value=1, inplace=True)\n",
    "    df[item].replace(to_replace='no',  value=0, inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can see TotalCharges is still an object. Fix TotalCharges as a float..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all entries for totalcharges field to numerics\n",
    "df['TotalCharges'] = df['TotalCharges'].replace(r'\\s+', np.nan, regex=True)\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for NULLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values on cols\n",
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna with zeros\n",
    "df = df.fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance the labels so we have the same number of non-churners as churners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churners_number = len(df[df['Churn'] == 1])\n",
    "print(\"Number of churners\", churners_number)\n",
    "\n",
    "churners = (df[df['Churn'] == 1])\n",
    "\n",
    "non_churners = df[df['Churn'] == 0].sample(n=churners_number)\n",
    "print(\"Number of non-churners\", len(non_churners))\n",
    "df2 = churners.append(non_churners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier\n",
    "\n",
    "Are there any strong correlations?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_correlations(dataframe, show_chart = True):\n",
    "    fig = plt.figure(figsize = (20,10))\n",
    "    corr = dataframe.corr()\n",
    "    if show_chart == True:\n",
    "        sns.heatmap(corr, \n",
    "                    xticklabels=corr.columns.values,\n",
    "                    yticklabels=corr.columns.values,\n",
    "                    annot=True)\n",
    "    return corr\n",
    "\n",
    "correlation_df = show_correlations(df2,show_chart=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Classifier\n",
    "Now, lets build a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    customer_id = df2['customerID'] # Store this as customer_id variable\n",
    "    del df2['customerID'] # Don't need in ML DF\n",
    "except:\n",
    "    print(\"already removed customerID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the dataframe head\n",
    "df2.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use one-hot encoding to convert categorical data to binary (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dummies\n",
    "ml_dummies = pd.get_dummies(df2)\n",
    "ml_dummies.fillna(value=0, inplace=True)\n",
    "ml_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a random column to the dataframe\n",
    "ml_dummies['---randomColumn---'] = np.random.randint(0,1000, size=len(ml_dummies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort values\n",
    "show_correlations(ml_dummies, show_chart=False)[\"Churn\"].sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the label before training\n",
    "try:\n",
    "    label = ml_dummies['Churn'] # Remove the label before training the model\n",
    "    del ml_dummies['Churn']\n",
    "except:\n",
    "    print(\"label already removed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using KNeighborsClassifier and DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "feature_train, feature_test, label_train, label_test = train_test_split(ml_dummies, label, test_size=0.3)\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(5),    \n",
    "    DecisionTreeClassifier(max_depth=5)\n",
    "]\n",
    "    \n",
    "\n",
    "# iterate over classifiers\n",
    "for item in classifiers:\n",
    "    classifier_name = ((str(item)[:(str(item).find(\"(\"))]))\n",
    "    print (classifier_name)\n",
    "    \n",
    "    # Create classifier, train it and test it.\n",
    "    clf = item\n",
    "    clf.fit(feature_train, label_train)\n",
    "    pred = clf.predict(feature_test)\n",
    "    score = clf.score(feature_test, label_test)\n",
    "    print (round(score,3),\"\\n\", \"- - - - - \", \"\\n\")\n",
    "    \n",
    "feature_df = pd.DataFrame()\n",
    "feature_df['features'] = ml_dummies.columns\n",
    "feature_df['importance'] = clf.feature_importances_\n",
    "feature_df.sort_values(by='importance', ascending=False)    \n",
    "feature_df.set_index(keys='features').sort_values(by='importance', ascending=True).plot(kind='barh', figsize=(20, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix\n",
    "Plot the confusion matrix, with some non-normalized matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(label_test, pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "class_names = ['Not churned','churned']\n",
    "\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "eval_metrics = classification_report(label_test, pred, target_names=class_names)\n",
    "print(eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digging some more on the results\n",
    "This result seems conservative. We're more likely to say someone is going to churn when they're not vs predicting someone's not going to churn when they do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search to tweak parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "max_depth_range = range(2,20,2)\n",
    "leaf_range = range(1,10,2)\n",
    "n_estimators_range = range(10,200,10)\n",
    "max_features_range = range(1,len(ml_dummies.columns),5)\n",
    "\n",
    "\n",
    "param_grid = dict(max_depth = max_depth_range,\n",
    "                 min_samples_leaf = leaf_range,\n",
    "                 n_estimators = n_estimators_range,\n",
    "                 max_features = max_features_range\n",
    "                )\n",
    "\n",
    "### Warning, can take some time\n",
    "\n",
    "# d_tree = RandomForestClassifier()\n",
    "# grid = GridSearchCV(d_tree, param_grid, cv=5, scoring = 'accuracy', verbose=1, return_train_score=True)\n",
    "# grid.fit(feature_train, label_train)\n",
    "# print (grid.best_score_)\n",
    "# print (grid.best_params_)\n",
    "# print (grid.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing original dataframe\n",
    "def preprocess_df(dataframe):\n",
    "    x = dataframe.copy()\n",
    "    try:\n",
    "        customer_id = x['customerID']\n",
    "        del x['customerID'] # Don't need in ML DF\n",
    "    except:\n",
    "        print(\"already removed customerID\")\n",
    "    ml_dummies = pd.get_dummies(x)\n",
    "    ml_dummies.fillna(value=0, inplace=True)\n",
    "\n",
    "    # import random done above\n",
    "    ml_dummies['---randomColumn---'] = np.random.randint(0,1000, size=len(ml_dummies))\n",
    "\n",
    "    try:\n",
    "        label = ml_dummies['Churn']\n",
    "        del ml_dummies['Churn']\n",
    "    except:\n",
    "        print(\"label already removed.\")\n",
    "    return ml_dummies, customer_id, label\n",
    "\n",
    "original_df = preprocess_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = original_df[0].copy()\n",
    "output_df['---randomColumn---']\n",
    "output_df['prediction'] = clf.predict_proba(output_df)[:,1]\n",
    "output_df['churn'] = original_df[2]\n",
    "output_df['customerID'] = original_df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean predict proba of churn:',round(output_df[output_df['churn'] == 1]['prediction'].mean(),2))\n",
    "\n",
    "print('Mean predict proba of NON-churn:',round(output_df[output_df['churn'] == 0]['prediction'].mean(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use this next dataframe for activation. \n",
    "Using media, let's target the customers who haven't churned but are likely to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate\n",
    "activate = output_df[output_df['churn'] == 0]\n",
    "activate[['customerID','churn','prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
